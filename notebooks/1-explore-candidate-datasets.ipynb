{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring a candidate data set\n",
    "==============================\n",
    "\n",
    "*Fraida Fund*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "------------\n",
    "\n",
    "In this notebook, we will consider several machine learning tasks\n",
    "(satirical headline classification, chest X-ray classification, and\n",
    "candidate data sets for them. We will explore the following questions:\n",
    "\n",
    "-   Do these data sets seem appropriate for the task?\n",
    "-   Are there any important limitations of the datasets, or problems\n",
    "    that need addressing before we use them to train a machine learning\n",
    "    model?\n",
    "\n",
    "In fact, each of these datasets has a significant problem that - if not\n",
    "detected early on - would be a “Garbage In, Garbage Out” situation. See\n",
    "if you can identify the problem with each dataset!\n",
    "\n",
    "To get you started, I included some code to show you how to read in the\n",
    "data. You can add additional code and text cells to explore the data. If\n",
    "you find something interesting, share it on Piazza!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taxi tip prediction\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "\n",
    "You are developing an app for NYC taxi drivers that will predict what\n",
    "the typical tip would be for a given fare. You consider using data\n",
    "collected by the NYC Taxi and Limousine Commission on taxi trips. The\n",
    "links are for 2019 data, but previous years are also available. [Data\n",
    "link for yellow (Manhattan) taxi\n",
    "trips](https://data.cityofnewyork.us/Transportation/2019-Yellow-Taxi-Trip-Data/2upf-qytp)\n",
    "and [data link for green (non-Manhattan) taxi\n",
    "trips](https://data.cityofnewyork.us/Transportation/2019-Green-Taxi-Trip-Data/q5mz-t52e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "We’ll start by reading in the 2019 Green Taxi trip data. It’s a large\n",
    "file and takes a long time to download, so we may interrupt the download\n",
    "in middle (using the Runtime menu in Colab) and just work with the\n",
    "partial data.\n",
    "\n",
    "In the next couple of cells, `wget` and `wc` are not Python code -\n",
    "they’re Linux commands. We can run some basic Linux commands inside our\n",
    "Colab runtime, and it’s often helpful to do so. For example, we may use\n",
    "Linux commands to install extra software libraries that are not\n",
    "pre-installed in our runtime, clone a source code repository from\n",
    "Github, or download data from the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://data.cityofnewyork.us/api/views/q5mz-t52e/rows.csv?accessType=DOWNLOAD\" -O 2019-Green-Taxi-Trip-Data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the cell above taking a long time to run? That’s because this data\n",
    "set is very large, and the server from which it is retrieved is not very\n",
    "fast. Since we don’t need to explore the whole dataset, necessarily, we\n",
    "can interrupt the partial download by clicking on the square icon to the\n",
    "left of the cell that is running.\n",
    "\n",
    "Then, we can read in just 10,000 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = pd.read_csv('2019-Green-Taxi-Trip-Data.csv', nrows=10000)   \n",
    "df_taxi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highway traffic prediction\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "\n",
    "You are working for the state of New York to develop a traffic\n",
    "prediction model for the NYS Thruway. The following Thruway data is\n",
    "available: Number and types of vehicles that entered from each entry\n",
    "point on the Thruway, along with their exit points, at 15 minute\n",
    "intervals. The link points to the most recent week’s worth of available\n",
    "data, but this data is available through 2014. [Link to NYS Thruway\n",
    "data](https://data.ny.gov/Transportation/NYS-Thruway-Origin-and-Destination-Points-for-All-/4dbf-24u2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.ny.gov/api/views/4dbf-24u2/rows.csv?accessType=DOWNLOAD&sorting=true'\n",
    "df_thruway = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satirical headline classification\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "\n",
    "You are hired by a major social media platform to develop a machine\n",
    "learning model that will be used to clearly mark *satirical news\n",
    "articles* when they are shared on social media. You consider using this\n",
    "dataset of 9,000 headlines from [The Onion](https://www.theonion.com/)\n",
    "and 15,000 headlines from [Not The Onion on\n",
    "Reddit](https://www.reddit.com/r/nottheonion/). [Link to OnionOrNot\n",
    "data](https://github.com/lukefeilberg/onion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "This time, we’ll retrieve the data from Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/lukefeilberg/onion.git\n",
    "%cd onion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_headline = pd.read_csv(\"OnionOrNot.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offensive post classification\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "\n",
    "The social media platform was so impressed with your work on detection\n",
    "of satirical headlines, that they asked you to work on a model to\n",
    "identify posts using offensive language. As training data, they hand you\n",
    "80,000 tweets, labeled as either “hateful”, “abusive”, “spam”, or\n",
    "“none”, by majority vote of five people. [Link to abusive tweets\n",
    "data](https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "This time, we’ll read in data to Colab by downloading it to our own\n",
    "computer from the link above, then uploading it to Colab.\n",
    "\n",
    "Use the interactive file upload form below to upload the\n",
    "`hatespeechtwitter.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('hatespeechtwitter.csv')\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chest X-ray classification\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "\n",
    "You are working for a large hospital system to develop a machine\n",
    "learning model that, given a chest X-ray, should identify those that\n",
    "likely have COVID-19 so that they can take proper precautions against\n",
    "the spread of infection within the hospital. You consider using two\n",
    "datasets together: one with several hundred images of chest X-rays of\n",
    "likely COVID-19 patients, and a pre-COVID dataset of chest X-ray images.\n",
    "[Link to COVID-19 chest X-ray\n",
    "data](https://github.com/ieee8023/covid-chestxray-dataset), [Link to\n",
    "pre-COVID chest X-ray\n",
    "data](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "First, we will download the RSNA data from the [RSNA\n",
    "website](https://www.rsna.org/en/education/ai-resources-and-training/ai-image-challenge/RSNA-Pneumonia-Detection-Challenge-2018).\n",
    "\n",
    "Then, we’ll also retrieve the COVID-19 data from Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/east1.public.rsna.org/AI/2018/pneumonia-challenge-dataset-adjudicated-kaggle_2018.zip -O pneumonia-challenge-dataset-adjudicated-kaggle_2018.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir rsna\n",
    "!unzip -j -d rsna/ pneumonia-challenge-dataset-adjudicated-kaggle_2018.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we’ll make a list of all the image files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "rsna_images = glob.glob(\"rsna/*.dcm\")\n",
    "len(rsna_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsna_images[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These images are in DICOM format, a medical imaging file format. We need\n",
    "to install an extra library to read them in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can read in one file from the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_xray = dicom.read_file(rsna_images[0])\n",
    "ref_xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(ref_xray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll find out the dimensions of the image, then represent it as an\n",
    "array of pixels, and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_dims = (int(ref_xray.Rows), int(ref_xray.Columns))\n",
    "pixel_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_xray.pixel_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref_xray.pixel_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ref_xray.pixel_array, cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COVID-19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ieee8023/covid-chestxray-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_metadata = pd.read_csv('covid-chestxray-dataset/metadata.csv')\n",
    "covid_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_metadata.modality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_metadata.finding.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re going to pull out a subset of the data that (1) is a chest X-ray,\n",
    "not CT, and (2) has a positive COVID-19 finding,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_xray_metadata = covid_metadata[(covid_metadata[\"modality\"] == \"X-ray\") & (covid_metadata[\"finding\"] == \"COVID-19\")]\n",
    "covid_xray_metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of image files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_images = 'covid-chestxray-dataset/images/' +  covid_xray_metadata['filename']\n",
    "len(covid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use the PIL library to read in JPG and PNG files, and plot one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(covid_images[0])\n",
    "image_bw = image.convert('L') #  L is 8-bit pixels, black and white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.asarray(image_bw)\n",
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_bw, cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot samples of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "samples_per_class = 10\n",
    "figure = plt.figure(figsize=(samples_per_class*3, num_classes*3))\n",
    "\n",
    "# plot RSNA samples\n",
    "rsna_samples = np.random.choice(rsna_images, samples_per_class, replace=False)\n",
    "for i, sample in enumerate(rsna_samples):\n",
    "    plt_idx = i + 1\n",
    "    plt.subplot(num_classes, samples_per_class, plt_idx)\n",
    "    sample_img = dicom.read_file(sample).pixel_array\n",
    "    plt.imshow(sample_img, cmap='bone')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Non-COVID\")\n",
    "\n",
    "\n",
    "# plot COVID samples\n",
    "covid_samples = np.random.choice(covid_images, samples_per_class, replace=False)\n",
    "for i, sample in enumerate(covid_samples):\n",
    "    plt_idx = samples_per_class + i + 1\n",
    "    plt.subplot(num_classes, samples_per_class, plt_idx)\n",
    "    sample_img = Image.open(sample)\n",
    "    sample_image_bw = sample_img.convert('L')\n",
    "    plt.imshow(sample_image_bw, cmap='bone')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"COVID-19\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
