{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo: Convolutional neural networks on the “slash” dataset\n",
    "==========================================================\n",
    "\n",
    "*Fraida Fund*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we’ll look at an example of a task that is difficult for “classical” machine learning models, and difficult for fully connected neural networks, but easy for convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble, neighbors, linear_model, svm\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten, BatchNormalization, InputLayer, AvgPool2D, MaxPool2D, GlobalAvgPool2D\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slash dataset\n",
    "-----------------\n",
    "\n",
    "The “slash” dataset, developed by [Sophie Searcy](https://soph.info/slash-data), is a set of images, each of which includes a “slash” on a background of random noise. The data is divided into two classes according to whether the slash is downward facing or upward facing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_example(size=20, label=0):\n",
    "\n",
    "    max_s_pattern = int(size // 4)\n",
    "    s_pattern = 4\n",
    "    pattern = 1- np.eye(s_pattern)\n",
    "    if label:\n",
    "        pattern = pattern[:, ::-1]\n",
    "    ex = np.ones((size,size))\n",
    "    point_loc = np.random.randint(0, size - s_pattern + 1,\n",
    "                                  size=(2, ))  # random x,y point\n",
    "    ex[point_loc[0]:point_loc[0] + s_pattern, point_loc[1]:point_loc[1] +\n",
    "       s_pattern] = pattern  # set point to\n",
    "    ex = ex + .5*(np.random.rand(size, size) - .5)\n",
    "    np.clip(ex,0.,1., out=ex)\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "n_side = 30\n",
    "n_ex = 500 #number of examples in each class\n",
    "\n",
    "for i in range(n_ex):\n",
    "    examples.append(gen_example(size=n_side, label=0))\n",
    "    examples.append(gen_example(size=n_side, label=1))\n",
    "    \n",
    "y = np.array([0,1]*n_ex)\n",
    "x = np.stack(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "n_print = 10 # number of examples to show\n",
    "\n",
    "ex_indices = np.random.choice(len(y), n_print, replace=False)\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x[index,...], cmap='gray')\n",
    "    plt.title(f\"y = {y[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’l prepare training and test data in two formats:\n",
    "\n",
    "-   “flat” for traditional ML models and fully connected neural networks, which don’t care about the spatial arrangement of the features.\n",
    "-   “image” for convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.25)\n",
    "\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "x_train_img = x_train[...,np.newaxis]\n",
    "x_test_img = x_test[...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flat data shape:  \", x_train_flat.shape)\n",
    "print(\"Image data shape: \", x_train_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature data is in the range 0 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.min(), x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train logistic regression, random forest, KNN, SVM models\n",
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll try to train some classic ML models on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic\\n Regression\": linear_model.LogisticRegression(),\n",
    "    \"KNN-1\": neighbors.KNeighborsClassifier(n_neighbors=1),\n",
    "    \"KNN-3\": neighbors.KNeighborsClassifier(n_neighbors=3),\n",
    "    \"Random\\n Forest\": ensemble.RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM -\\n Linear\": svm.SVC(kernel=\"linear\"),\n",
    "    \"SVM -\\n RBF kernel\": svm.SVC(kernel=\"rbf\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name in models.keys():    \n",
    "    model = models[model_name]\n",
    "    model.fit(x_train_flat, y_train)\n",
    "    \n",
    "    train_score = model.score(x_train_flat, y_train)\n",
    "    test_score = model.score(x_test_flat, y_test)   \n",
    "    \n",
    "    results.append({\"model\": model_name, \"train_score\": train_score, \"test_score\": test_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize =(10,10));\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['train_score']);\n",
    "plt.ylim(0,1);\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['test_score']);\n",
    "plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these the results we expected? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do *any* of these models do a good job of learning whether a slash is forward-facing or backward-facing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a fully connected neural network\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nin = x_train_flat.shape[1]\n",
    "nh1 = 64\n",
    "nh2 = 64\n",
    "nh3 = 64  \n",
    "nout = 1 \n",
    "model_fc = Sequential()\n",
    "model_fc.add(Dense(units=nh1, input_shape=(nin,), activation='relu', name='hidden1'))\n",
    "model_fc.add(Dense(units=nh2, input_shape=(nh1,), activation='relu', name='hidden2'))\n",
    "model_fc.add(Dense(units=nh3, input_shape=(nh2,), activation='relu', name='hidden3'))\n",
    "model_fc.add(Dense(units=nout, activation='sigmoid', name='output'))\n",
    "\n",
    "model_fc.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_fc.fit(x_train_flat, y_train, epochs=100, \n",
    "     validation_split=0.25,  callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=.5, patience=2, verbose=1),\n",
    "        keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True, verbose=1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model_fc.evaluate(x_train_flat, y_train)[1]\n",
    "test_score = model_fc.evaluate(x_test_flat, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\"model\": 'FC Neural Net', \"train_score\": train_score, \"test_score\": test_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize =(11,10));\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['train_score']);\n",
    "plt.ylim(0,1);\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['test_score']);\n",
    "plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a convolutional neural network\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 10\n",
    "model_conv = Sequential()\n",
    "model_conv.add(InputLayer(input_shape=x_train_img.shape[1:]))\n",
    "model_conv.add(Conv2D(filters, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False ))\n",
    "model_conv.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_conv.add(BatchNormalization())\n",
    "model_conv.add(Conv2D(filters, kernel_size=3, padding=\"same\", activation=\"relu\", use_bias=False ))\n",
    "model_conv.add(GlobalAvgPool2D())\n",
    "model_conv.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_conv.summary()\n",
    "\n",
    "model_conv.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_conv.fit(x_train_img, y_train, epochs=100, \n",
    "     validation_split=0.25,  callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=.5, patience=2, verbose=1),\n",
    "        keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True, verbose=1)\n",
    "    ])\n",
    "\n",
    "train_score = model_conv.evaluate(x_train_img, y_train)[1]\n",
    "test_score = model_conv.evaluate(x_test_img, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\"model\": 'ConvNet', \"train_score\": train_score, \"test_score\": test_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize =(12,10));\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['train_score']);\n",
    "plt.ylim(0,1);\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['test_score']);\n",
    "plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same model on different slashes\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only did our convolutional network learn forward and backward slashes - it can even generalize to slightly different forward and backward slashes.\n",
    "\n",
    "Let’s generate data with heavier background noise, and longer slashes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = 0.65\n",
    "s_pattern = 15\n",
    "def gen_example_different(size=20, label=0):\n",
    "\n",
    "    max_s_pattern = int(size // 4)\n",
    "    pattern = 1- np.eye(s_pattern)\n",
    "    if label:\n",
    "        pattern = pattern[:, ::-1]\n",
    "    ex = np.ones((size,size))\n",
    "    point_loc = np.random.randint(0, size - s_pattern + 1,\n",
    "                                  size=(2, ))  # random x,y point\n",
    "    ex[point_loc[0]:point_loc[0] + s_pattern, point_loc[1]:point_loc[1] +\n",
    "       s_pattern] = pattern  # set point to\n",
    "    ex = ex + noise_scale*(np.random.rand(size, size) - .5)\n",
    "    np.clip(ex,0.,1., out=ex)\n",
    "    return ex\n",
    "\n",
    "examples = []\n",
    "\n",
    "n_side = 30\n",
    "n_ex = 50 #number of examples in each class\n",
    "\n",
    "for i in range(n_ex):\n",
    "    examples.append(gen_example_different(size=n_side, label=0))\n",
    "    examples.append(gen_example_different(size=n_side, label=1))\n",
    "    \n",
    "y_new = np.array([0,1]*n_ex)\n",
    "x_new = np.stack(examples)\n",
    "\n",
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "n_print = 10 # number of examples to show\n",
    "\n",
    "ex_indices = np.random.choice(len(y_new), n_print, replace=False)\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x_new[index,...], cmap='gray')\n",
    "    plt.title(f\"y = {y_new[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x_new[index,...], cmap='gray')\n",
    "    plt.title(\"yhat =  %0.2f\" % model_conv.predict(x_new[index].reshape((1,30,30,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_score = model_conv.evaluate(x_new[...,np.newaxis], y_new)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about forward and backward slashes at different angles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rot = 10\n",
    "def gen_example_rotated(size=20, label=0):\n",
    "\n",
    "    max_s_pattern = int(size // 4)\n",
    "    s_pattern = 15\n",
    "    pattern = 1- np.eye(s_pattern)\n",
    "    if label:\n",
    "        pattern = pattern[:, ::-1]\n",
    "    ex = np.ones((size,size))\n",
    "    point_loc = np.random.randint(0, size - s_pattern + 1,   size=(2, ))  \n",
    "    ex[point_loc[0]:point_loc[0] + s_pattern, point_loc[1]:point_loc[1] + s_pattern] = pattern  \n",
    "    rot_angle = np.random.uniform(-max_rot, max_rot)\n",
    "    ex = scipy.ndimage.rotate(ex, angle=rot_angle, cval=1, reshape = False)\n",
    "    ex = ex + noise_scale*(np.random.rand(size, size) - .5)\n",
    "\n",
    "    np.clip(ex,0.,1., out=ex)\n",
    "    return ex\n",
    "\n",
    "examples = []\n",
    "\n",
    "n_side = 30\n",
    "n_ex = 50 #number of examples in each class\n",
    "\n",
    "for i in range(n_ex):\n",
    "    examples.append(gen_example_rotated(size=n_side, label=0))\n",
    "    examples.append(gen_example_rotated(size=n_side, label=1))\n",
    "    \n",
    "y_new = np.array([0,1]*n_ex)\n",
    "x_new = np.stack(examples)\n",
    "\n",
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "n_print = 10 # number of examples to show\n",
    "\n",
    "ex_indices = np.random.choice(len(y_new), n_print, replace=False)\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x_new[index,...], cmap='gray')\n",
    "    plt.title(f\"y = {y_new[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x_new[index,...], cmap='gray')\n",
    "    plt.title(\"yhat =  %0.2f\" % model_conv.predict(x_new[index].reshape((1,30,30,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_score = model_conv.evaluate(x_new[...,np.newaxis], y_new)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing what the network learns\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "from ipywidgets import Layout\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plot_layer(test_idx, layer_idx):\n",
    "  convout1_f = K.function(model_conv.inputs, [model_conv.layers[layer_idx].output])\n",
    "  convolutions = np.squeeze(convout1_f(x[test_idx].reshape((1,30,30,1))))\n",
    "  if (len(convolutions.shape)) > 1:\n",
    "    m = convolutions.shape[2]\n",
    "    n = int(np.ceil(np.sqrt(m)))\n",
    "\n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(15,12))\n",
    "    print(model_conv.layers[layer_idx].name)\n",
    "    for i in range(m):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[:,:,i], cmap='gray')\n",
    "        ax.set_title(i)\n",
    "  else:\n",
    "    print(model_conv.layers[layer_idx].name)\n",
    "    plt.imshow(convolutions.reshape(1, convolutions.shape[0]), cmap='gray');\n",
    "    plt.yticks([])\n",
    "    plt.xticks(range(convolutions.shape[0]))\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "layout = Layout(width=\"800px\")\n",
    "test_idx = widgets.IntSlider(min=0, max=len(x)-1, value=0, style=style, layout=layout)\n",
    "layer_idx = widgets.IntSlider(min=0, max=len(model_conv.layers)-2, value=0, style=style, layout=layout)\n",
    "interactive(plot_layer, test_idx=test_idx, layer_idx=layer_idx)"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "colab": {
   "toc_visible": "true"
  }
 }
}
