{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Convolutional neural networks on the “slash” dataset\n",
    "\n",
    "*Fraida Fund*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we’ll look at an example of a task that is difficult for “classical” machine learning models, and difficult for fully connected neural networks, but easy for convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble, neighbors, linear_model, svm\n",
    "\n",
    "\n",
    "from ipywidgets import interactive, Layout, interact, IntSlider\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The slash dataset\n",
    "\n",
    "The “slash” dataset, developed by [Sophie Searcy](https://soph.info/slash-data), is a set of images, each of which includes a “slash” on a background of random noise. The data is divided into two classes according to whether the slash is downward facing or upward facing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_example(size=20, label=0):\n",
    "\n",
    "    max_s_pattern = int(size // 4)\n",
    "    s_pattern = 4\n",
    "    pattern = 1- np.eye(s_pattern)\n",
    "    if label:\n",
    "        pattern = pattern[:, ::-1]\n",
    "    ex = np.ones((size,size))\n",
    "    point_loc = np.random.randint(0, size - s_pattern + 1,\n",
    "                                  size=(2, ))  # random x,y point\n",
    "    ex[point_loc[0]:point_loc[0] + s_pattern, point_loc[1]:point_loc[1] +\n",
    "       s_pattern] = pattern  # set point to\n",
    "    ex = ex + .5*(np.random.rand(size, size) - .5)\n",
    "    np.clip(ex,0.,1., out=ex)\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "n_side = 30\n",
    "n_ex = 500 #number of examples in each class\n",
    "\n",
    "for i in range(n_ex):\n",
    "    examples.append(gen_example(size=n_side, label=0))\n",
    "    examples.append(gen_example(size=n_side, label=1))\n",
    "    \n",
    "y = np.array([0,1]*n_ex)\n",
    "x = np.stack(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "n_print = 10 # number of examples to show\n",
    "\n",
    "ex_indices = np.random.choice(len(y), n_print, replace=False)\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x[index,...], cmap='gray')\n",
    "    plt.title(f\"y = {y[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’l prepare training and test data in two formats:\n",
    "\n",
    "-   “flat” for traditional ML models and fully connected neural networks, which don’t care about the spatial arrangement of the features.\n",
    "-   “image” for convolutional neural networks, which expect the input to have a depth, height, and width. (The “depth” dimension is 1 for these grayscale images.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.25)\n",
    "\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "x_train_img = np.expand_dims(x_train, axis=1)  # shape [B, 1, H, W]\n",
    "x_test_img = np.expand_dims(x_test, axis=1)    # shape [B, 1, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flat data shape:  \", x_train_flat.shape)\n",
    "print(\"Image data shape: \", x_train_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature data is in the range 0 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.min(), x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic regression, random forest, KNN, SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll try to train some classic ML models on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic\\n Regression\": linear_model.LogisticRegression(),\n",
    "    \"KNN-1\": neighbors.KNeighborsClassifier(n_neighbors=1),\n",
    "    \"KNN-3\": neighbors.KNeighborsClassifier(n_neighbors=3),\n",
    "    \"Random\\n Forest\": ensemble.RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM -\\n Linear\": svm.SVC(kernel=\"linear\"),\n",
    "    \"SVM -\\n RBF kernel\": svm.SVC(kernel=\"rbf\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name in models.keys():    \n",
    "    model = models[model_name]\n",
    "    model.fit(x_train_flat, y_train)\n",
    "    \n",
    "    train_score = model.score(x_train_flat, y_train)\n",
    "    test_score = model.score(x_test_flat, y_test)   \n",
    "    \n",
    "    results.append({\"model\": model_name, \"train_score\": train_score, \"test_score\": test_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize =(10,10));\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['train_score']);\n",
    "plt.ylim(0,1);\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['test_score']);\n",
    "plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these the results we expected? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do *any* of these models do a good job of learning whether a slash is forward-facing or backward-facing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a fully connected neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will set up a fully connected neural network in Pytorch:\n",
    "\n",
    "-   it will accept a flat array of all pixels in the slash image as input (we’ll pass that when we create an instance of the model)\n",
    "-   it will have three hidden layers, each with 64 fully connected units\n",
    "-   it will use a ReLU activation at the hidden layers\n",
    "-   it will have one output unit with a sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNet(nn.Module):\n",
    "    def __init__(self, nin, nh1=64, nh2=64, nh3=64, nout=1):\n",
    "        super(FCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(nin, nh1)\n",
    "        self.fc2 = nn.Linear(nh1, nh2)\n",
    "        self.fc3 = nn.Linear(nh2, nh3)\n",
    "        self.out = nn.Linear(nh3, nout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll set up the `DataLoader` to feed images in batches for training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(x_train_flat, dtype=torch.float32), \n",
    "    torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(x_test_flat, dtype=torch.float32), \n",
    "    torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re going to prefer to train this model on a GPU. So before we start, we will\n",
    "\n",
    "-   check if a GPU is available (a “cuda” device) with `torch.cuda.is_available()`\n",
    "-   if a GPU is available, set `device` to the GPU device; otherwise set it to the CPU device\n",
    "-   create an instance of the fully connected model, and *move it to the device*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_fc = FCNet(nin=x_train_flat.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can specify the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train it for 100 epochs.\n",
    "\n",
    "Within each epoch, we will iterate over the training `DataLoader`, passing a batch of data at a time to the model. We will *move the data to the `device`* - since the model is moved to GPU (if one is avaliable), the data also must be moved to GPU.\n",
    "\n",
    "Then, we do our forward pass and backwards pass, and update the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "model_fc.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model_fc(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our model is trained, let’s evaluate it on both the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc.eval()\n",
    "train_preds, train_targets = [], []\n",
    "test_preds, test_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model_fc(xb)\n",
    "        train_preds.append(preds.cpu())\n",
    "        train_targets.append(yb)\n",
    "\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model_fc(xb)\n",
    "        test_preds.append(preds.cpu())\n",
    "        test_targets.append(yb)\n",
    "\n",
    "train_preds = torch.cat(train_preds).numpy()\n",
    "train_targets = torch.cat(train_targets).numpy()\n",
    "test_preds = torch.cat(test_preds).numpy()\n",
    "test_targets = torch.cat(test_targets).numpy()\n",
    "\n",
    "train_score = ((train_preds > 0.5).astype(int).flatten() == train_targets.flatten()).mean()\n",
    "test_score = ((test_preds > 0.5).astype(int).flatten() == test_targets.flatten()).mean()\n",
    "\n",
    "print(f\"Train Accuracy: {train_score:.4f}\")\n",
    "print(f\"Test Accuracy: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\"model\": 'FC Neural Net', \"train_score\": train_score, \"test_score\": test_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize =(11,10));\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['train_score']);\n",
    "plt.ylim(0,1);\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['test_score']);\n",
    "plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this model has tens of thousands of parameters, it does not do very well on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(\n",
    "    param.numel() for param in model_fc.parameters()\n",
    ")\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model_fc.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we’ll try a convolutional neural network:\n",
    "\n",
    "-   it will accept as input a 3D volume, although in this case the depth dimension is 1 (there are no color channels)\n",
    "-   it will have the following sequence of hidden layers:\n",
    "    -   a convolution layer with 8 filters, 3x3 size, zero-padding 1, and ReLU activation\n",
    "    -   a max pooling layer with 2x2 filter size\n",
    "    -   a batch normalization layer\n",
    "    -   another convolution layer with the same settings\n",
    "    -   a “global” average pooling layer, that returns the average of the entire output from each filter in the previous layer\n",
    "    -   and finally, a fully connected layer connected to the output unit\n",
    "-   it will have one output unit with a sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, filters=8):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, filters, kernel_size=3, padding=1, bias=False)  # [B, 1, H, W] -> [B, 8, H, W]\n",
    "        self.relu1 = nn.ReLU() \n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)  # [B, 8, H, W] -> [B, 8, H/2, W/2]\n",
    "        self.bn = nn.BatchNorm2d(filters)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, padding=1, bias=False)  # [B, 8, H/2, W/2]\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)  # [B, 8, H/2, W/2] -> [B, 8, 1, 1]\n",
    "        self.fc = nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)         # [B, 8, H, W]\n",
    "        x = self.relu1(x)         # [B, 8, H, W]\n",
    "        x = self.pool(x)          # [B, 8, H/2, W/2]\n",
    "        x = self.bn(x)            # [B, 8, H/2, W/2]\n",
    "        x = self.conv2(x)         # [B, 8, H/2, W/2]\n",
    "        x = self.relu2(x)         # [B, 8, H/2, W/2]\n",
    "        x = self.global_avg_pool(x)  # [B, 8, 1, 1]\n",
    "        x = x.view(x.size(0), -1)    # [B, 8]\n",
    "        x = torch.sigmoid(self.fc(x))  # [B, 1]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll set up the `DataLoader` to feed images in batches for training and evaluation - this time, with spatial dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(x_train_img, dtype=torch.float32), \n",
    "    torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(x_test_img, dtype=torch.float32), \n",
    "    torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we’ll put the model on GPU if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_conv = ConvNet(in_channels=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can specify the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_conv.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "model_conv.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model_conv(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our model is trained, let’s evaluate it on both the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.eval()\n",
    "train_preds, train_targets = [], []\n",
    "test_preds, test_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model_conv(xb)\n",
    "        train_preds.append(preds.cpu())\n",
    "        train_targets.append(yb)\n",
    "\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model_conv(xb)\n",
    "        test_preds.append(preds.cpu())\n",
    "        test_targets.append(yb)\n",
    "\n",
    "train_preds = torch.cat(train_preds).numpy()\n",
    "train_targets = torch.cat(train_targets).numpy()\n",
    "test_preds = torch.cat(test_preds).numpy()\n",
    "test_targets = torch.cat(test_targets).numpy()\n",
    "\n",
    "train_score = ((train_preds > 0.5).astype(int).flatten() == train_targets.flatten()).mean()\n",
    "test_score = ((test_preds > 0.5).astype(int).flatten() == test_targets.flatten()).mean()\n",
    "\n",
    "print(f\"Train Accuracy: {train_score:.4f}\")\n",
    "print(f\"Test Accuracy: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\"model\": 'ConvNet', \"train_score\": train_score, \"test_score\": test_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize =(12,10));\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['train_score']);\n",
    "plt.ylim(0,1);\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.barplot(x=results_df.sort_values('test_score')['model'], y=results_df.sort_values('test_score')['test_score']);\n",
    "plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does the convolutional neural network do much better than the fully connected neural network at recognizing the orientation of a “slash”, it also has only a tiny fraction of its size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(\n",
    "    param.numel() for param in model_conv.parameters()\n",
    ")\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model_conv.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the same model on different slashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only did our convolutional network learn forward and backward slashes - it can even generalize to slightly different forward and backward slashes.\n",
    "\n",
    "Let’s generate data with heavier background noise, and longer slashes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = 0.65\n",
    "s_pattern = 15\n",
    "def gen_example_different(size=20, label=0):\n",
    "\n",
    "    max_s_pattern = int(size // 4)\n",
    "    pattern = 1- np.eye(s_pattern)\n",
    "    if label:\n",
    "        pattern = pattern[:, ::-1]\n",
    "    ex = np.ones((size,size))\n",
    "    point_loc = np.random.randint(0, size - s_pattern + 1,\n",
    "                                  size=(2, ))  # random x,y point\n",
    "    ex[point_loc[0]:point_loc[0] + s_pattern, point_loc[1]:point_loc[1] +\n",
    "       s_pattern] = pattern  # set point to\n",
    "    ex = ex + noise_scale*(np.random.rand(size, size) - .5)\n",
    "    np.clip(ex,0.,1., out=ex)\n",
    "    return ex\n",
    "\n",
    "examples = []\n",
    "\n",
    "n_side = 30\n",
    "n_ex = 50 #number of examples in each class\n",
    "\n",
    "for i in range(n_ex):\n",
    "    examples.append(gen_example_different(size=n_side, label=0))\n",
    "    examples.append(gen_example_different(size=n_side, label=1))\n",
    "    \n",
    "y_new = np.array([0,1]*n_ex)\n",
    "x_new = np.stack(examples)\n",
    "\n",
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "n_print = 10 # number of examples to show\n",
    "\n",
    "ex_indices = np.random.choice(len(y_new), n_print, replace=False)\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x_new[index,...], cmap='gray')\n",
    "    plt.title(f\"y = {y_new[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x_new[index,...], cmap='gray')\n",
    "\n",
    "    x_new_tensor = torch.tensor(x_new[index][np.newaxis, np.newaxis, :, :], dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        yhat = model_conv(x_new_tensor).cpu().item()  # scalar output\n",
    "\n",
    "    plt.title(f\"yhat = {yhat:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_tensor = torch.tensor(x_new[:, np.newaxis, :, :], dtype=torch.float32).to(device)  # shape [N, 1, H, W]\n",
    "y_new_tensor = torch.tensor(y_new, dtype=torch.float32).unsqueeze(1).to(device)          # shape [N, 1]\n",
    "\n",
    "model_conv.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model_conv(x_new_tensor)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "    correct = (y_pred_class == y_new_tensor).float().sum().item()\n",
    "    total = y_new_tensor.size(0)\n",
    "    new_test_score = correct / total\n",
    "\n",
    "print(f\"New test accuracy: {new_test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about forward and backward slashes at different angles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rot = 10\n",
    "def gen_example_rotated(size=20, label=0):\n",
    "\n",
    "    max_s_pattern = int(size // 4)\n",
    "    s_pattern = 15\n",
    "    pattern = 1- np.eye(s_pattern)\n",
    "    if label:\n",
    "        pattern = pattern[:, ::-1]\n",
    "    ex = np.ones((size,size))\n",
    "    point_loc = np.random.randint(0, size - s_pattern + 1,   size=(2, ))  \n",
    "    ex[point_loc[0]:point_loc[0] + s_pattern, point_loc[1]:point_loc[1] + s_pattern] = pattern  \n",
    "    rot_angle = np.random.uniform(-max_rot, max_rot)\n",
    "    ex = scipy.ndimage.rotate(ex, angle=rot_angle, cval=1, reshape = False)\n",
    "    ex = ex + noise_scale*(np.random.rand(size, size) - .5)\n",
    "\n",
    "    np.clip(ex,0.,1., out=ex)\n",
    "    return ex\n",
    "\n",
    "examples = []\n",
    "\n",
    "n_side = 30\n",
    "n_ex = 50 #number of examples in each class\n",
    "\n",
    "for i in range(n_ex):\n",
    "    examples.append(gen_example_rotated(size=n_side, label=0))\n",
    "    examples.append(gen_example_rotated(size=n_side, label=1))\n",
    "    \n",
    "y_new = np.array([0,1]*n_ex)\n",
    "x_new = np.stack(examples)\n",
    "\n",
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "n_print = 10 # number of examples to show\n",
    "\n",
    "ex_indices = np.random.choice(len(y_new), n_print, replace=False)\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x_new[index,...], cmap='gray')\n",
    "    plt.title(f\"y = {y_new[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "\n",
    "for i, index in enumerate(ex_indices):\n",
    "    plt.subplot(1, n_print, i+1, )\n",
    "    plt.imshow(x_new[index,...], cmap='gray')\n",
    "\n",
    "    x_new_tensor = torch.tensor(x_new[index][np.newaxis, np.newaxis, :, :], dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        yhat = model_conv(x_new_tensor).cpu().item()  # scalar output\n",
    "\n",
    "    plt.title(f\"yhat = {yhat:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_tensor = torch.tensor(x_new[:, np.newaxis, :, :], dtype=torch.float32).to(device)  # shape [N, 1, H, W]\n",
    "y_new_tensor = torch.tensor(y_new, dtype=torch.float32).unsqueeze(1).to(device)          # shape [N, 1]\n",
    "\n",
    "model_conv.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model_conv(x_new_tensor)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "    correct = (y_pred_class == y_new_tensor).float().sum().item()\n",
    "    total = y_new_tensor.size(0)\n",
    "    new_test_score = correct / total\n",
    "\n",
    "print(f\"New test accuracy: {new_test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize what the network learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ### Visualization magic\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, IntSlider\n",
    "from IPython.display import display\n",
    "\n",
    "activations = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach().cpu()\n",
    "    return hook\n",
    "\n",
    "layer_names = []\n",
    "for name, layer in model_conv.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        # Register pre-activation (conv output)\n",
    "        pre_name = f\"{name}_pre\"\n",
    "        layer.register_forward_hook(get_activation(pre_name))\n",
    "        layer_names.append(pre_name)\n",
    "\n",
    "    if isinstance(layer, (nn.ReLU, nn.MaxPool2d, nn.AdaptiveAvgPool2d)):\n",
    "        # Register after activations\n",
    "        layer.register_forward_hook(get_activation(name))\n",
    "        layer_names.append(name)\n",
    "\n",
    "# Visualize function\n",
    "def visualize_layer(test_idx=0, layer_idx=0):\n",
    "    model_conv.eval()\n",
    "    x_img = x_test[test_idx]  # shape: [H, W]\n",
    "    x_tensor = torch.tensor(x_img[np.newaxis, np.newaxis], dtype=torch.float32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _ = model_conv(x_tensor)  # triggers hooks\n",
    "\n",
    "    name = layer_names[layer_idx]\n",
    "    fmap = activations[name].squeeze(0)  # remove batch dim\n",
    "\n",
    "    n_channels = fmap.shape[0]\n",
    "    \n",
    "    if fmap.ndim == 1 or (fmap.shape[1:] == torch.Size([1, 1])):\n",
    "        fmap_flat = fmap.view(-1).numpy()\n",
    "        plt.figure(figsize=(len(fmap_flat) * 0.5, 0.5))\n",
    "        plt.imshow(fmap_flat[np.newaxis, :], cmap='gray', aspect='auto')\n",
    "        plt.title(f\"{name} (Global Avg Pool Output)\")\n",
    "        plt.yticks([])\n",
    "        plt.xticks(range(len(fmap_flat)))\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    n_cols = int(np.ceil(np.sqrt(n_channels)))\n",
    "    n_rows = int(np.ceil(n_channels / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, n_rows * 2))\n",
    "    fig.suptitle(name)\n",
    "    \n",
    "    for i in range(n_channels):\n",
    "        ax = axes.flat[i]\n",
    "        ax.imshow(fmap[i], cmap='gray')\n",
    "        ax.set_title(f\"{i}\", fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "    # hide unused axes\n",
    "    for i in range(n_channels, len(axes.flat)):\n",
    "        axes.flat[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Sliders to choose image and layer\n",
    "widget = interact(\n",
    "    visualize_layer,\n",
    "    test_idx=IntSlider(0, 0, len(x_test)-1, step=1, description='Test Index'),\n",
    "    layer_idx=IntSlider(0, 0, len(layer_names)-1, step=1, description='Layer Index')\n",
    ")"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 }
}
