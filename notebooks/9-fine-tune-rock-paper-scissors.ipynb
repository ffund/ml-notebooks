{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Transfer learning\n",
    "\n",
    "*Fraida Fund*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, for most machine learning problems, you wouldn’t design or train a convolutional neural network from scratch - you would use an existing model that suits your needs (does well on ImageNet, size is right) and fine-tune it on your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for faster training, use Runtime \\> Change Runtime Type to run this notebook on a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells that follow, we’ll get the “rock paper scissors” data, plot a few examples, and also prepare a preprocessing function (which we won’t apply yet). The preprocessing transforms will:\n",
    "\n",
    "-   resize each sample to 224x224 (this is a typical input size for pretrained models trained on ImageNet)\n",
    "-   and normalize input using the mean and standard deviation of ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request, zipfile\n",
    "\n",
    "urls = {\n",
    "    'train': \"https://storage.googleapis.com/download.tensorflow.org/data/rps.zip\",\n",
    "    'test':  \"https://storage.googleapis.com/download.tensorflow.org/data/rps-test-set.zip\"\n",
    "}\n",
    "data_dir = \"./data/rps\"\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "for split, url in urls.items():\n",
    "    zip_path = os.path.join(data_dir, f\"{split}.zip\")\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"Downloading {split} set...\")\n",
    "        urllib.request.urlretrieve(url, zip_path)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "            z.extractall(os.path.join(data_dir, split))\n",
    "        print(f\"{split} set extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = os.path.join(data_dir, 'train', 'rps')\n",
    "test_root  = os.path.join(data_dir, 'test', 'rps-test-set')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_root, transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(root=test_root, transform=transform)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "mean = torch.tensor(imagenet_mean).view(3, 1, 1)\n",
    "std = torch.tensor(imagenet_std).view(3, 1, 1)\n",
    "\n",
    "idxs = np.random.choice(len(train_dataset), n, replace=False)\n",
    "\n",
    "plt.figure(figsize=(n * 2, 2))\n",
    "for i, idx in enumerate(idxs):\n",
    "    img, label = train_dataset[idx]\n",
    "    img = img * std + mean  # de-normalize\n",
    "    img = img.permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify with a ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[torchvision models](https://docs.pytorch.org/vision/0.9/models.html) image models that have been pre-trained on ImageNet. You can download their saved weights, and use in your own code.\n",
    "\n",
    "We are going to use a pre-trained ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.resnet18(weights='ResNet18_Weights.DEFAULT').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels\n",
    "labels_url = 'https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt'\n",
    "labels_path = 'imagenet_classes.txt'\n",
    "if not os.path.exists(labels_path):\n",
    "    urllib.request.urlretrieve(labels_url, labels_path)\n",
    "\n",
    "with open(labels_path) as f:\n",
    "    class_labels = [line.strip() for line in f]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see what the top 5 predicted classes are for my test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.eval()\n",
    "with torch.no_grad():\n",
    "    output = base_model(test_tensor.to(device))              # [1, 1000]\n",
    "    probs = F.softmax(output, dim=1)\n",
    "    top_prob, top_idx = probs[0].topk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes = [class_labels[i] for i in top_idx.tolist()]\n",
    "top_probs = top_prob.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.barplot(x=top_classes, y=top_probs)\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_title(\"Top-5 Predictions\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base model is trained on a specific task: classifying the images in the ImageNet dataset by selecting the most appropriate of 1000 class labels.\n",
    "\n",
    "It is not trained for our specific task: classifying an image of a hand as rock, paper, or scissors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: fine-tuning a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical convolutional neural network looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Visualization/PlotNeuralNet/vgg16.png\" alt=\"Image via PlotNeuralNet\" />\n",
    "<figcaption aria-hidden=\"true\">Image via <a href=\"https://github.com/HarisIqbal88/PlotNeuralNet\">PlotNeuralNet</a></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a sequence of convolutional layers followed by pooling layers. These layers are *feature extractors* that “learn” key features of our input images.\n",
    "\n",
    "Then, we have one or more fully connected layers followed by a fully connected layer with a softmax activation function. This part of the network is for *classification*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key idea behind transfer learning is that the *feature extractor* part of the network can be re-used across different tasks and different domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is especially useful when we don’t have a lot of task-specific data. We can get a pre-trained feature extractor trained on a lot of data from another task, then train the classifier on task-specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general process is:\n",
    "\n",
    "-   Get a pre-trained model, without the classification layer.\n",
    "-   Freeze the base model.\n",
    "-   Add a classification layer.\n",
    "-   Train the model (only the weights in your classification layer will be updated).\n",
    "-   (Optional) Un-freeze some of the last layers in your base model.\n",
    "-   (Optional) Train the model again, with a smaller learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our own classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will\n",
    "\n",
    "-   get the base model,\n",
    "-   freeze the weights in the feature extraction part,\n",
    "-   and put a brand-new, totally untrained classification head on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in transfer_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the classification head at the end\n",
    "num_ftrs = transfer_model.fc.in_features\n",
    "transfer_model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(num_ftrs, 3)  # 3 classes: rock, paper, scissors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = transfer_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(\n",
    "    param.numel() for param in transfer_model.parameters()\n",
    ")\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in transfer_model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply data augmentation and preprocessing to the training data; and just preprocessing to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation for training set\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])\n",
    "\n",
    "# no augmentation for test set\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_root, transform=aug_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=test_root,  transform=basic_transform)\n",
    "class_names   = train_dataset.classes\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start training our model. Remember, we are *only* updating the weights in the classification head.\n",
    "\n",
    "Also note that we are reporting loss on the test data in each epoch, but we are not doing early stopping or otherwise “using” this. If we were using this loss to make decisions about the training process, we would have to split out a separate validation set to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transfer_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train on training set\n",
    "    transfer_model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = transfer_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_losses.append(total_loss / total)\n",
    "    train_accuracies.append(correct / total)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    transfer_model.eval()\n",
    "    test_loss, test_correct, test_total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = transfer_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            test_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "    test_losses.append(test_loss / test_total)\n",
    "    test_accuracies.append(test_correct / test_total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_losses[-1]:.4f}, Acc: {train_accuracies[-1]*100:.2f}% | \"\n",
    "          f\"Test Loss: {test_losses[-1]:.4f}, Acc: {test_accuracies[-1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(train_losses, marker='o', label='Train Loss')\n",
    "plt.plot(test_losses, marker='s', label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have fitted our own classification head, but there's one more step we can attempt to customize the model for our particular application.\n",
    "\n",
    "We are going to “un-freeze” the later parts of the model, and train it for a few more epochs on our data, so that the high-level features are better suited for our specific classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last n_unfreeze layers of the feature extractor\n",
    "# Unfreeze last residual block (layer4)\n",
    "for param in transfer_model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "transfer_model = transfer_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(\n",
    "    param.numel() for param in transfer_model.parameters()\n",
    ")\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in transfer_model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fine-tune these additional parameters using a smaller learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(transfer_model.parameters(), lr=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are *not* creating a new model. We’re just going to continue training the model we already started training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_fine = 20\n",
    "\n",
    "for epoch in range(num_epochs + 1, num_epochs + num_epochs_fine + 1):\n",
    "    # Train on training set\n",
    "    transfer_model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = transfer_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_losses.append(total_loss / total)\n",
    "    train_accuracies.append(correct / total)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    transfer_model.eval()\n",
    "    test_loss, test_correct, test_total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = transfer_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            test_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "    test_losses.append(test_loss / test_total)\n",
    "    test_accuracies.append(test_correct / test_total)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs + num_epochs_fine} | \"\n",
    "          f\"Train Loss: {train_losses[-1]:.4f}, Acc: {train_accuracies[-1]*100:.2f}% | \"\n",
    "          f\"Test Loss: {test_losses[-1]:.4f}, Acc: {test_accuracies[-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, marker='o', label='Train Loss')\n",
    "plt.plot(test_losses, marker='s', label='Test Loss')\n",
    "\n",
    "# vertical dashed line to mark fine-tuning start\n",
    "plt.axvline(x=num_epochs - 1, color='gray', linestyle='--', label='Fine-tuning start')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify custom test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also upload a personal example, in PNG format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    " \n",
    "# Edit the filename here as needed\n",
    "filename = 'scissors.png'\n",
    " \n",
    "# pre-process image\n",
    "image = Image.open(filename).convert('RGB')\n",
    "test_tensor = transform(image).unsqueeze(0)  # shape: [1, 3, 224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.eval()\n",
    "with torch.no_grad():\n",
    "    output = transfer_model(test_tensor.to(device))         # [1, 3]\n",
    "    pred_label = output.argmax(dim=1).item()                # integer label\n",
    "\n",
    "# Map class index to class name\n",
    "pred_class = class_names[pred_label]  # e.g., \"rock\", \"paper\", \"scissors\"\n",
    "\n",
    "# De-normalize and plot\n",
    "mean = torch.tensor(imagenet_mean).view(3, 1, 1)\n",
    "std = torch.tensor(imagenet_std).view(3, 1, 1)\n",
    "\n",
    "img = test_tensor.squeeze(0).cpu() * std + mean\n",
    "img_np = img.permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img_np)\n",
    "plt.title(f\"Prediction: {pred_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, for most machine learning problems, you wouldn’t design or train a convolutional neural network from scratch - you would use an existing model that suits your needs (does well on ImageNet, size is right) and fine-tune it on your own data."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 }
}
