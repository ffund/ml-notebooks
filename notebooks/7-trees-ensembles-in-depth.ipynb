{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo: Decision trees and ensembles\n",
    "==================================\n",
    "\n",
    "*Fraida Fund*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple demo notebook that demonstrates a decision tree classifier or an ensemble of decision trees.\n",
    "\n",
    "**Attribution**: Parts of this notebook are slightly modified from [this tutorial from “Intro to Data Mining”](http://www.cse.msu.edu/~ptan/dmbook/tutorials/tutorial6/tutorial6.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://www.cse.msu.edu/~ptan/dmbook/tutorials/tutorial6/vertebrate.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’l make it a binary classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class'].replace(['fishes','birds','amphibians','reptiles'],'non-mammals')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "X = df.drop(['Name','Class'],axis=1)\n",
    "\n",
    "clf_dt = DecisionTreeClassifier(criterion='entropy')\n",
    "clf_dt = clf_dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sklearn.tree.plot_tree(clf_dt, \n",
    "                    feature_names = df.columns.drop(['Name', 'Class']),\n",
    "                    class_names = [\"mammals\", \"non-mammals\"],\n",
    "                    filled=True, rounded=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame({'feature': df.columns.drop(['Name', 'Class']),\n",
    "                              'importance': clf_dt.feature_importances_})\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged tree\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tree = 3\n",
    "clf_bag = BaggingClassifier(n_estimators=n_tree)\n",
    "clf_bag = clf_bag.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(n_tree*8, 10))\n",
    "for idx, clf_t in enumerate(clf_bag.estimators_):\n",
    "  plt.subplot(1, n_tree,idx+1)\n",
    "  sklearn.tree.plot_tree(clf_t, \n",
    "                      feature_names = df.columns.drop(['Name', 'Class']),\n",
    "                      class_names = [\"mammals\", \"non-mammals\"],\n",
    "                      filled=True, rounded=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the similarities! The bagged trees are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at the bootstrap sets each tree was trained on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samples in clf_bag.estimators_samples_:\n",
    "  print(df.iloc[samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tree = 3\n",
    "clf_rf = RandomForestClassifier(n_estimators=n_tree, )\n",
    "clf_rf = clf_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(n_tree*8, 10))\n",
    "for idx, clf_t in enumerate(clf_rf.estimators_):\n",
    "  plt.subplot(1, n_tree,idx+1)\n",
    "  sklearn.tree.plot_tree(clf_t, \n",
    "                      feature_names = df.columns.drop(['Name', 'Class']),\n",
    "                      class_names = [\"mammals\", \"non-mammals\"],\n",
    "                      filled=True, rounded=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These trees are much less correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tree = 3\n",
    "clf_ab = AdaBoostClassifier(n_estimators=n_tree)\n",
    "clf_ab = clf_ab.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(n_tree*8, 10))\n",
    "for idx, clf_t in enumerate(clf_ab.estimators_):\n",
    "  plt.subplot(1, n_tree,idx+1)\n",
    "  sklearn.tree.plot_tree(clf_t, \n",
    "                      feature_names = df.columns.drop(['Name', 'Class']),\n",
    "                      class_names = [\"mammals\", \"non-mammals\"],\n",
    "                      filled=True, rounded=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will be a weighted average of the predictions of all three trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we add more trees, the ensemble accuracy increases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in clf_ab.staged_predict(X):\n",
    "  print(np.mean(p==y))"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "colab": {
   "toc_visible": "true"
  }
 }
}
